{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LFnT2MWe1IPx"
      },
      "outputs": [],
      "source": [
        "##### DOWNLOAD DATASET #####\n",
        "from IPython.display import clear_output\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "!ls -lha kaggle.json\n",
        "!pip install -q kaggle # installing the kaggle package\n",
        "!mkdir -p ~/.kaggle # creating .kaggle folder where the key should be placed\n",
        "!cp kaggle.json ~/.kaggle/ # move the key to the folder\n",
        "!pwd # checking the present working directory\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d gsimonx37/letterboxd\n",
        "!unzip /content/letterboxd.zip -d /content/letterbox/\n",
        "clear_output()\n",
        "############################"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########### SPARK CONTEXT #####################\n",
        "import pandas as pd\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # Property used to format output tables better\n",
        "\n",
        "sc = spark.sparkContext\n",
        "###############################################"
      ],
      "metadata": {
        "id": "FPDSHZ_ydWnr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############## BASKET CREATION ################\n",
        "#TODO do it using SPARK directly -> cars = spark.read.csv('cars.csv', header=True, sep=\";\")\n",
        "actors = pd.read_csv(\"letterbox/actors.csv\")\n",
        "actors = actors\n",
        "baskets = actors.groupby(\"id\")[\"name\"].apply(list)\n",
        "#baskets = baskets.sample(10000)\n",
        "\n",
        "print(\"number of baskets: \" + str(len(baskets)))\n",
        "print(\"biggest basket: \" + str(baskets.map(len).max()))\n",
        "print(baskets)\n",
        "baskets_RDD = sc.parallelize(baskets).cache()\n",
        "##############################################"
      ],
      "metadata": {
        "id": "7S860HiwhKp1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "833c5348-05f1-43a2-d4e2-47a0d68f4f8f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of baskets: 603163\n",
            "biggest basket: 451\n",
            "id\n",
            "1000001    [Margot Robbie, Lewis Easter, Onyemachi Ejimof...\n",
            "1000002    [Rosie Peralta, Anna Elisabeth Rihlmann, Andre...\n",
            "1000003    [Randall Archer, Boon Pin Koh, Efka Kvaracieju...\n",
            "1000004    [Leonard Termo, Greg Bronson, Michael Arturo, ...\n",
            "1000005    [Lena Georgas, Jeff Hephner, Elyes Gabel, Broo...\n",
            "                                 ...                        \n",
            "1896377    [Marat Basharov, Sergey Rost, Gleb Kalyuzhny, ...\n",
            "1896382                                   [Marine Petrosyan]\n",
            "1896387                                        [Rebecca Jim]\n",
            "1896391                                       [Ko Shibasaki]\n",
            "1896393                                    [Atsuhiro Inukai]\n",
            "Name: name, Length: 603163, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_basket = [\n",
        "    ['a','b','c','d','e','f','g','h','i','l'],\n",
        "    ['n','o'],\n",
        "    ['o','n'],\n",
        "    ['a','b','c','d','e','f',],\n",
        "    ['a','b','c'],\n",
        "    ['f','q'],\n",
        "    ['f','q','z'],\n",
        "    ['f','u','q'],\n",
        "    ['n','o','i'],\n",
        "    ['a','b','c','d','e','f','q','p','o','n'],\n",
        "    ['a','b','c','d','e','f','r','s','t','u'],\n",
        "]\n",
        "test_RDD = sc.parallelize(test_basket).cache()"
      ],
      "metadata": {
        "id": "YnHnwobrBe0d"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## APRIORI\n",
        "def apriori(chunk, s, tot_bsk):\n",
        "\n",
        "  n_bsk = 0 # number of baskets in chunk used to calculate support\n",
        "#  trsl = dict() # using a translation could be better for the combination step\n",
        "  count = dict() # should be relatively efficient since is a hash table\n",
        "\n",
        "#\n",
        "#  def translate(e, dic):\n",
        "#    try:\n",
        "#      return dic[e]\n",
        "#    except KeyError:\n",
        "#      dic[e] = len(dic)+1\n",
        "#      return dic[e]\n",
        "  def incr(e,dic):\n",
        "    try:\n",
        "      dic[e] += 1;\n",
        "    except KeyError:\n",
        "      dic[e] = 1\n",
        "\n",
        "  chunk = list(chunk) # to avoid consuming after first pass\n",
        "  ### first pass\n",
        "  for bsk in chunk:\n",
        "    n_bsk += 1;\n",
        "    #elements = [translate(x,trsl) for x in bsk]\n",
        "    for b in bsk:\n",
        "      incr(b,count)\n",
        "\n",
        "  ### filter\n",
        "  to_del = []\n",
        "  frequent = []\n",
        "  for c in count:\n",
        "    if count[c] >= s* n_bsk/tot_bsk:\n",
        "      frequent.append(c)\n",
        "      #yield (c,1)\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  #frequent = list(count.keys())\n",
        "  #yield (len(frequent),1)\n",
        "\n",
        "  frequent.sort()\n",
        "  cmb = list(itertools.combinations(frequent,2)) #It's probably more efficient to\n",
        "  #yield (len(cmb),1)\n",
        "\n",
        "  count_2 = dict()\n",
        "  ### second pass\n",
        "  for bsk in chunk:\n",
        "    for pair in cmb: #this already solve the ordering problem if the list is ordered\n",
        "      if pair[0] in bsk and pair[1] in bsk:\n",
        "        incr(tuple(pair), count_2)\n",
        "\n",
        "  to_del = []\n",
        "  frequent = []\n",
        "  for c in count_2:\n",
        "    if count_2[c] < (s * n_bsk)/tot_bsk:\n",
        "      to_del.append(c)\n",
        "    else:\n",
        "      frequent.append(c)\n",
        "      yield(c,1)\n",
        "  for t in to_del:\n",
        "    del count_2[t]\n",
        "  \"\"\"\n",
        "  k = 2\n",
        "  while True:#len(frequent) > 0:\n",
        "    print(frequent)\n",
        "    if len(frequent) == 0:\n",
        "      break\n",
        "    frequent.sort()\n",
        "    #cmb = list(itertools.combinations(frequent, 3))\n",
        "    count = dict()\n",
        "\n",
        "    for bsk in tqdm(chunk):\n",
        "      #print('basket')\n",
        "      #bsk = [x for x in bsk if x in frequent] #filter only members of Ck\n",
        "      filtered = set()\n",
        "      for b in bsk:\n",
        "        for f in frequent:\n",
        "          if b in f:\n",
        "            filtered.add(b)\n",
        "            break;\n",
        "      bsk = list(filtered)\n",
        "      #print('bsk:'+str(bsk))\n",
        "      bsk.sort()\n",
        "      for tpl in itertools.combinations(bsk, k):\n",
        "          incr(tuple(tpl), count)\n",
        "\n",
        "    frequent = []\n",
        "    for c in count:\n",
        "      if count[c] >= s * n_bsk/tot_bsk:\n",
        "        frequent.append(c)\n",
        "        yield(c,1)\n",
        "    #print(len(frequent))\n",
        "    k+=1\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RieQuIkAo7c_"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real = []\n",
        "for a in apriori(test_basket,5,len(test_basket)):\n",
        "  real.append(a)\n",
        "print(real)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUg8ywWFD-IO",
        "outputId": "ce279309-375e-493d-de29-e5a4daa95a38"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'b', 'c', 'f']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:00<00:00, 45907.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('a', 'b'), ('a', 'c'), ('b', 'c')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:00<00:00, 51093.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('a', 'b', 'c')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:00<00:00, 61028.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "[(('a', 'b'), 1), (('a', 'c'), 1), (('b', 'c'), 1), (('a', 'b', 'c'), 1)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "S =  5; #support threshold (maybe a fraction is better)\n",
        "TOT = len(test_basket)#len(baskets)\n",
        "\n",
        "#baskets_RDD\n",
        "#SON first step\n",
        "candidates = test_RDD.mapPartitions(lambda x: apriori(x,S,TOT)).reduceByKey(lambda a,b: a).keys().collect()\n",
        "print(candidates)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMhukWkCZLND",
        "outputId": "2f230128-a87e-4c74-fa90-74d304a2f4e6"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('b', 'c'), ('a', 'b', 'c'), ('f', 'q'), ('a', 'b'), ('a', 'c')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "not_real = [x for x in candidates if x not in real]\n",
        "not_present = [x for x in real if x not in candidates]\n",
        "print(not_real)\n",
        "print(not_present)"
      ],
      "metadata": {
        "id": "n9ZSuiiWQxfM",
        "outputId": "b3e3077e-e4e7-428b-c99a-d0cb17d9effa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(('f', 'q'), 1)]\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_candidates = [('b','c'), ('a','b','c'), ('f','q'), ('a','b'), ('a','c')]\n",
        "#SON second step\n",
        "def second_map(chunk,itemset,s):\n",
        "  def incr(e,dic):\n",
        "    try:\n",
        "      dic[e] += 1;\n",
        "    except KeyError:\n",
        "      dic[e] = 1\n",
        "\n",
        "  count = dict()\n",
        "  for bsk in tqdm(chunk):\n",
        "    for i in itemset:\n",
        "      flag = True\n",
        "      for e in i:\n",
        "        if e not in bsk:\n",
        "          flag = False\n",
        "          break\n",
        "      if flag:\n",
        "        incr(i,count)\n",
        "  for c in count:\n",
        "    yield (c,count[c])\n",
        "\n",
        "real_from_candidates = test_RDD.mapPartitions(lambda x: second_map(x, test_candidates,S)).reduceByKey(lambda a,b: a+b).filter(lambda a: a[1] >= S).keys().collect()\n",
        "print(real_from_candidates)\n",
        "for r in real_from_candidates:\n",
        "  print(r)\n",
        "#for i in second_map(test_basket, test_candidates,s):\n",
        "#  print(i)"
      ],
      "metadata": {
        "id": "VSa3ABzYCu9G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0cb03ff-ccc6-4986-e69e-bb7a6d9a3ef3"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('b', 'c'), ('a', 'b', 'c'), ('a', 'b'), ('a', 'c')]\n",
            "('b', 'c')\n",
            "('a', 'b', 'c')\n",
            "('a', 'b')\n",
            "('a', 'c')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFibA15uBEEN",
        "outputId": "b7504920-3574-4598-8cb6-2c0cbc43c37d"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t7SPM_7SZuQW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}